[
["index.html", "Pythonで始める機械学習のRによる学習 まえおき", " Pythonで始める機械学習のRによる学習 R. Ito 2018-03-25 まえおき やるぞい(੭•̀ᴗ•̀)੭ "],
["hoshin.html", "方針とか", " 方針とか Pythonではじめる機械学習 ―scikit-learnで学ぶ特徴量エンジニアリングと機械学習の基礎をRのmlrパッケージでやっていきたい気持ち。 see also: Pythonで始める機械学習の学習 "],
["1-.html", "1 はじめに", " 1 はじめに library(mlr) ## 要求されたパッケージ ParamHelpers をロード中です ## Warning: replacing previous import &#39;BBmisc::isFALSE&#39; by ## &#39;backports::isFALSE&#39; when loading &#39;mlr&#39; 細かいところは飛ばしていきます。 "],
["1-1-.html", "1.1 必要なライブラリとツール", " 1.1 必要なライブラリとツール mlr Rで機械学習と言えばこれという説がある。 チュートリアルを訳したもの: mlrパッケージチュートリアル - Quick Walkthrough編 ggplot2 プロット用パッケージ。 GGally ggplot2を使って散布図行列等が簡単に作成できるパッケージ。 "],
["1-2-.html", "1.2 最初のアプリケーション: アイリスのクラス分類", " 1.2 最初のアプリケーション: アイリスのクラス分類 みんな大好きiris Rでは最初からirisを使える。 head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa irisをヘルプに渡せばデータの解説も得られる。 ?irisでも良い。 help(iris) ## _E_d_g_a_r _A_n_d_e_r_s_o_n&#39;_s _I_r_i_s _D_a_t_a ## ## _D_e_s_c_r_i_p_t_i_o_n: ## ## This famous (Fisher&#39;s or Anderson&#39;s) iris data set gives the ## measurements in centimeters of the variables sepal length and ## width and petal length and width, respectively, for 50 flowers ## from each of 3 species of iris. The species are _Iris setosa_, ## _versicolor_, and _virginica_. ## ## _U_s_a_g_e: ## ## iris ## iris3 ## ## _F_o_r_m_a_t: ## ## &#39;iris&#39; is a data frame with 150 cases (rows) and 5 variables ## (columns) named &#39;Sepal.Length&#39;, &#39;Sepal.Width&#39;, &#39;Petal.Length&#39;, ## &#39;Petal.Width&#39;, and &#39;Species&#39;. ## ## &#39;iris3&#39; gives the same data arranged as a 3-dimensional array of ## size 50 by 4 by 3, as represented by S-PLUS. The first dimension ## gives the case number within the species subsample, the second the ## measurements with names &#39;Sepal L.&#39;, &#39;Sepal W.&#39;, &#39;Petal L.&#39;, and ## &#39;Petal W.&#39;, and the third the species. ## ## _S_o_u_r_c_e: ## ## Fisher, R. A. (1936) The use of multiple measurements in taxonomic ## problems. _Annals of Eugenics_, *7*, Part II, 179-188. ## ## The data were collected by Anderson, Edgar (1935). The irises of ## the Gaspe Peninsula, _Bulletin of the American Iris Society_, ## *59*, 2-5. ## ## _R_e_f_e_r_e_n_c_e_s: ## ## Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S ## Language_. Wadsworth &amp; Brooks/Cole. (has &#39;iris3&#39; as &#39;iris&#39;.) ## ## _S_e_e _A_l_s_o: ## ## &#39;matplot&#39; some examples of which use &#39;iris&#39;. ## ## _E_x_a_m_p_l_e_s: ## ## dni3 &lt;- dimnames(iris3) ## ii &lt;- data.frame(matrix(aperm(iris3, c(1,3,2)), ncol = 4, ## dimnames = list(NULL, sub(&quot; L.&quot;,&quot;.Length&quot;, ## sub(&quot; W.&quot;,&quot;.Width&quot;, dni3[[2]])))), ## Species = gl(3, 50, labels = sub(&quot;S&quot;, &quot;s&quot;, sub(&quot;V&quot;, &quot;v&quot;, dni3[[3]])))) ## all.equal(ii, iris) # TRUE ## 1.2.1 最初にすべきこと: データをよく観察する 訓練セットとテストセットに分割してからプロットする必要も無いと思うので、先に散布図行列を作成する。ここではggplot2を使って散布図行列を作成するGGallyパッケージを使用した。 GGally::ggpairs( iris, ggplot2::aes(color = Species), upper = list(continuous = GGally::wrap(&quot;cor&quot;, size = 2.5)), lower = list(combo = GGally::wrap(&quot;facethist&quot;, bins = 20)) ) 1.2.2 成功度合いの測定: 訓練データとテストデータ 雑な感じで3:1にデータを分割する。 n &lt;- nrow(iris) iris_train &lt;- sample(n, size = 3/4 * n) iris_test &lt;- setdiff(1:n, iris_train) 1.2.3 最初のモデル: \\(k\\)-最近傍法 sklearnよろしく、まず学習器のインスタンスを生成する。 \\(k\\)=1のkNNからということなので、そのようにする。 lrn &lt;- makeLearner( &quot;classif.knn&quot;, k = 1 ) lrn ## Learner classif.knn from package class ## Type: classif ## Name: k-Nearest Neighbor; Short name: knn ## Class: classif.knn ## Properties: twoclass,multiclass,numerics ## Predict-Type: response ## Hyperparameters: k=1 学習器を作成したらデータをフィットさせて訓練する。 ## まずタスクを作成する必要がある iris_task &lt;- makeClassifTask(data = iris, target = &quot;Species&quot;) ## 訓練する mod &lt;- train(lrn, iris_task, subset = iris_train) mod ## Model for learner.id=classif.knn; learner.class=classif.knn ## Trained on: task.id = iris; obs = 112; features = 4 ## Hyperparameters: k=1 1.2.4 予測を行う 予測はpredictで行う。 predict(mod, newdata = data.frame(5, 2.9, 1, 0.2)) ## Prediction: 1 observations ## predict.type: response ## threshold: ## time: 0.00 ## response ## 1 setosa setosaと予測されたがこれが正しい分類かどうかわからない…。この時のためにテストデータをとっておいたのだった。 1.2.5 モデルの評価 テストデータを使った予測結果とテストデータの真のクラスラベルを比較する。 テストデータのうち正しく分類できたものの割合を精度と呼ぶ。 mlrではpredictにタスクとsubsetを指定すると、subsetに対して指定したインデックスで予測を行い、予測されたクラスラベルと正解のクラスラベルを合わせて返してくれる。 pred &lt;- predict(mod, task = iris_task, subset = iris_test) pred ## Prediction: 38 observations ## predict.type: response ## threshold: ## time: 0.00 ## id truth response ## 2 2 setosa setosa ## 4 4 setosa setosa ## 10 10 setosa setosa ## 13 13 setosa setosa ## 19 19 setosa setosa ## 21 21 setosa setosa ## ... (38 rows, 3 cols) 従って、精度を求めるにはtruthとresponseの値の一致率を見ればよい。 mean(pred$data$truth == pred$data$response) ## [1] 0.9473684 無論、性能指標を計算するための関数も用意されている。予測結果をperformanceに渡せば良い。 performance(pred, measures = list(mmce, acc)) # 計算する指標を指定している ## mmce acc ## 0.05263158 0.94736842 "]
]
