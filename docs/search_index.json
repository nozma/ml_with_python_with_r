[
["index.html", "Pythonで始める機械学習のRによる学習 まえおき", " Pythonで始める機械学習のRによる学習 R. Ito 2018-03-26 まえおき やるぞい(੭•̀ᴗ•̀)੭ "],
["hoshin.html", "方針とか", " 方針とか Pythonではじめる機械学習 ―scikit-learnで学ぶ特徴量エンジニアリングと機械学習の基礎をRのmlrパッケージでやっていきたい気持ち。 see also: Pythonで始める機械学習の学習 "],
["1-はじめに.html", "1 はじめに", " 1 はじめに library(mlr) ## Loading required package: ParamHelpers 細かいところは飛ばしていきます。 "],
["1-1-必要なライブラリとツール.html", "1.1 必要なライブラリとツール", " 1.1 必要なライブラリとツール mlr Rで機械学習と言えばこれという説がある。 チュートリアルを訳したもの: mlrパッケージチュートリアル - Quick Walkthrough編 ggplot2 プロット用パッケージ。 GGally ggplot2を使って散布図行列等が簡単に作成できるパッケージ。 reticulate RからPython使うやつ。 "],
["1-2-最初のアプリケーション-アイリスのクラス分類.html", "1.2 最初のアプリケーション: アイリスのクラス分類", " 1.2 最初のアプリケーション: アイリスのクラス分類 みんな大好きiris Rでは最初からirisを使える。 head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa irisをヘルプに渡せばデータの解説も得られる。 ?irisでも良い。 help(iris) ## _E_d_g_a_r _A_n_d_e_r_s_o_n&#39;_s _I_r_i_s _D_a_t_a ## ## _D_e_s_c_r_i_p_t_i_o_n: ## ## This famous (Fisher&#39;s or Anderson&#39;s) iris data set gives the ## measurements in centimeters of the variables sepal length and ## width and petal length and width, respectively, for 50 flowers ## from each of 3 species of iris. The species are _Iris setosa_, ## _versicolor_, and _virginica_. ## ## _U_s_a_g_e: ## ## iris ## iris3 ## ## _F_o_r_m_a_t: ## ## &#39;iris&#39; is a data frame with 150 cases (rows) and 5 variables ## (columns) named &#39;Sepal.Length&#39;, &#39;Sepal.Width&#39;, &#39;Petal.Length&#39;, ## &#39;Petal.Width&#39;, and &#39;Species&#39;. ## ## &#39;iris3&#39; gives the same data arranged as a 3-dimensional array of ## size 50 by 4 by 3, as represented by S-PLUS. The first dimension ## gives the case number within the species subsample, the second the ## measurements with names &#39;Sepal L.&#39;, &#39;Sepal W.&#39;, &#39;Petal L.&#39;, and ## &#39;Petal W.&#39;, and the third the species. ## ## _S_o_u_r_c_e: ## ## Fisher, R. A. (1936) The use of multiple measurements in taxonomic ## problems. _Annals of Eugenics_, *7*, Part II, 179-188. ## ## The data were collected by Anderson, Edgar (1935). The irises of ## the Gaspe Peninsula, _Bulletin of the American Iris Society_, ## *59*, 2-5. ## ## _R_e_f_e_r_e_n_c_e_s: ## ## Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S ## Language_. Wadsworth &amp; Brooks/Cole. (has &#39;iris3&#39; as &#39;iris&#39;.) ## ## _S_e_e _A_l_s_o: ## ## &#39;matplot&#39; some examples of which use &#39;iris&#39;. ## ## _E_x_a_m_p_l_e_s: ## ## dni3 &lt;- dimnames(iris3) ## ii &lt;- data.frame(matrix(aperm(iris3, c(1,3,2)), ncol = 4, ## dimnames = list(NULL, sub(&quot; L.&quot;,&quot;.Length&quot;, ## sub(&quot; W.&quot;,&quot;.Width&quot;, dni3[[2]])))), ## Species = gl(3, 50, labels = sub(&quot;S&quot;, &quot;s&quot;, sub(&quot;V&quot;, &quot;v&quot;, dni3[[3]])))) ## all.equal(ii, iris) # TRUE ## 1.2.1 最初にすべきこと: データをよく観察する 訓練セットとテストセットに分割してからプロットする必要も無いと思うので、先に散布図行列を作成する。ここではggplot2を使って散布図行列を作成するGGallyパッケージを使用した。 GGally::ggpairs( iris, ggplot2::aes(color = Species), upper = list(continuous = GGally::wrap(&quot;cor&quot;, size = 2.5)), lower = list(combo = GGally::wrap(&quot;facethist&quot;, bins = 20)) ) 1.2.2 成功度合いの測定: 訓練データとテストデータ 雑な感じで3:1にデータを分割する。 n &lt;- nrow(iris) iris_train &lt;- sample(n, size = 3/4 * n) iris_test &lt;- setdiff(1:n, iris_train) 1.2.3 最初のモデル: \\(k\\)-最近傍法 sklearnよろしく、まず学習器のインスタンスを生成する。 \\(k\\)=1のkNNからということなので、そのようにする。 lrn &lt;- makeLearner( &quot;classif.knn&quot;, k = 1 ) lrn ## Learner classif.knn from package class ## Type: classif ## Name: k-Nearest Neighbor; Short name: knn ## Class: classif.knn ## Properties: twoclass,multiclass,numerics ## Predict-Type: response ## Hyperparameters: k=1 学習器を作成したらデータをフィットさせて訓練する。 ## まずタスクを作成する必要がある iris_task &lt;- makeClassifTask(data = iris, target = &quot;Species&quot;) ## 訓練する mod &lt;- train(lrn, iris_task, subset = iris_train) mod ## Model for learner.id=classif.knn; learner.class=classif.knn ## Trained on: task.id = iris; obs = 112; features = 4 ## Hyperparameters: k=1 1.2.4 予測を行う 予測はpredictで行う。 predict(mod, newdata = data.frame(5, 2.9, 1, 0.2)) ## Prediction: 1 observations ## predict.type: response ## threshold: ## time: 0.00 ## response ## 1 setosa setosaと予測されたがこれが正しい分類かどうかわからない…。この時のためにテストデータをとっておいたのだった。 1.2.5 モデルの評価 テストデータを使った予測結果とテストデータの真のクラスラベルを比較する。 テストデータのうち正しく分類できたものの割合を精度と呼ぶ。 mlrではpredictにタスクとsubsetを指定すると、subsetに対して指定したインデックスで予測を行い、予測されたクラスラベルと正解のクラスラベルを合わせて返してくれる。 pred &lt;- predict(mod, task = iris_task, subset = iris_test) pred ## Prediction: 38 observations ## predict.type: response ## threshold: ## time: 0.00 ## id truth response ## 2 2 setosa setosa ## 4 4 setosa setosa ## 10 10 setosa setosa ## 13 13 setosa setosa ## 19 19 setosa setosa ## 21 21 setosa setosa ## ... (#rows: 38, #cols: 3) 従って、精度を求めるにはtruthとresponseの値の一致率を見ればよい。 mean(pred$data$truth == pred$data$response) ## [1] 0.9473684 無論、性能指標を計算するための関数も用意されている。予測結果をperformanceに渡せば良い。 performance(pred, measures = list(mmce, acc)) # 計算する指標を指定している ## mmce acc ## 0.05263158 0.94736842 "],
["2-教師あり学習-1.html", "2 教師あり学習 (1)", " 2 教師あり学習 (1) 長くなりそうなので分割。おそらく決定木あたりまで。 library(mlr) ## Loading required package: ParamHelpers library(reticulate) # pythonモジュールからデータだけいただく用 use_python(&quot;/usr/bin/python3&quot;) library(ggplot2) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(magrittr) theme_set(theme_bw(base_family = &quot;IPAexGothic&quot;)) # ggplot2の日本語プロット用 library(mlbench) library(mlrCPO) "],
["2-1-教師あり機械学習アルゴリズム.html", "2.1 教師あり機械学習アルゴリズム", " 2.1 教師あり機械学習アルゴリズム 2.1.1 サンプルデータセット 2.1.1.1 人工的なデータセット 書籍の方ではmgleranモジュールを使ってデータを生成しているので、reticulateをデータだけ取得する。 まずは2クラス分類向けのforgeを取得し、プロットする。 mglearn &lt;- import(&quot;mglearn&quot;) forge &lt;- mglearn$datasets$make_forge() forge %&lt;&gt;% as.data.frame() names(forge)[3] &lt;- &quot;y&quot; ggplot(forge, aes(x = X1, y = X2, color = factor(y))) + scale_color_discrete(name = &quot;クラス&quot;) + labs(x = &quot;第1特徴量&quot;, y = &quot;第2特徴量&quot;) + geom_point() 次に回帰向けのデータセットwaveを取得し、プロットする。 wave &lt;- mglearn$datasets$make_wave(n_samples = 40L) wave %&lt;&gt;% as.data.frame() names(wave) &lt;- c(&quot;X&quot;, &quot;y&quot;) ggplot(wave, aes(X, y)) + geom_point() + labs(x = &quot;特徴量&quot;, y = &quot;出力&quot;) 2.1.1.2 実世界のデータセット breast cancerもboston housingもmlbenchパッケージに含まれているが、breast cancerの方はsklearnに入っているものと若干異なる。breast cancerにはOriginalとDiagnosticの2種類あるらしい。sklearnに入っているのはDiagnosticで、mlbenchのやつはOriginal。 UCI Machine Learning Repository: Breast Cancer Wisconsin (Original) Data Set UCI Machine Learning Repository: Breast Cancer Wisconsin (Diagnostic) Data Set Diagnosticの方は少し探したけどRの中には見つからなかったので(代わりにOriginalがMASS::biopsyにもあるのを見つけた)、sklearnから読み込んで細工しておく。 sklearn &lt;- import(&quot;sklearn&quot;) cancer = sklearn$datasets$load_breast_cancer() cancer_data &lt;- as.data.frame(cancer$data) # データフレーム化 names(cancer_data) &lt;- cancer$feature_names # 特徴量名取り込み cancer_data$Class &lt;- cancer$target_names[cancer$target+1] # クラス取り込み breast cancerは569のデータポイントと30の特徴量を持つ。 dim(cancer_data) # クラスも含めているので列数は1多い ## [1] 569 31 各クラスの集計をする。 table(cancer_data$Class) ## ## benign malignant ## 357 212 boston housingはmlbenchパッケージ内のものとsklearnのものは同じなので、そのまま使用できる。 data(&quot;BostonHousing&quot;) head(BostonHousing) ## crim zn indus chas nox rm age dis rad tax ptratio b ## 1 0.00632 18 2.31 0 0.538 6.575 65.2 4.0900 1 296 15.3 396.90 ## 2 0.02731 0 7.07 0 0.469 6.421 78.9 4.9671 2 242 17.8 396.90 ## 3 0.02729 0 7.07 0 0.469 7.185 61.1 4.9671 2 242 17.8 392.83 ## 4 0.03237 0 2.18 0 0.458 6.998 45.8 6.0622 3 222 18.7 394.63 ## 5 0.06905 0 2.18 0 0.458 7.147 54.2 6.0622 3 222 18.7 396.90 ## 6 0.02985 0 2.18 0 0.458 6.430 58.7 6.0622 3 222 18.7 394.12 ## lstat medv ## 1 4.98 24.0 ## 2 9.14 21.6 ## 3 4.03 34.7 ## 4 2.94 33.4 ## 5 5.33 36.2 ## 6 5.21 28.7 次に、特徴量同士の積を重複ありで選択して拡張する、という作業が出て来る。書籍の方ではmglearnの影に隠れてしまっているが、これはsklearn.preprocessing.PolynomialFeaturesという関数の機能によっている。 これに近いことは、mlrCPOパッケージのcpoModelMatrix関数を使うと実行できる。mlrCPOパッケージはまだCRANには無いので、devtools::install_github(&quot;mlr-org/mlrCPO&quot;)のようにgithubからインストールする必要がある。 boston_task &lt;- makeRegrTask(data = BostonHousing, target = &quot;medv&quot;) boston_task_ex &lt;- boston_task %&gt;&gt;% cpoModelMatrix(~ 0 + .^2) boston_task_ex ## Supervised task: BostonHousing ## Type: regr ## Target: medv ## Observations: 506 ## Features: ## numerics factors ordered functionals ## 92 0 0 0 ## Missings: FALSE ## Has weights: FALSE ## Has blocking: FALSE ## Has coordinates: FALSE getTaskFeatureNames(boston_task_ex) ## [1] &quot;crim&quot; &quot;zn&quot; &quot;indus&quot; &quot;chas0&quot; ## [5] &quot;chas1&quot; &quot;nox&quot; &quot;rm&quot; &quot;age&quot; ## [9] &quot;dis&quot; &quot;rad&quot; &quot;tax&quot; &quot;ptratio&quot; ## [13] &quot;b&quot; &quot;lstat&quot; &quot;crim:zn&quot; &quot;crim:indus&quot; ## [17] &quot;crim:chas1&quot; &quot;crim:nox&quot; &quot;crim:rm&quot; &quot;crim:age&quot; ## [21] &quot;crim:dis&quot; &quot;crim:rad&quot; &quot;crim:tax&quot; &quot;crim:ptratio&quot; ## [25] &quot;crim:b&quot; &quot;crim:lstat&quot; &quot;zn:indus&quot; &quot;zn:chas1&quot; ## [29] &quot;zn:nox&quot; &quot;zn:rm&quot; &quot;zn:age&quot; &quot;zn:dis&quot; ## [33] &quot;zn:rad&quot; &quot;zn:tax&quot; &quot;zn:ptratio&quot; &quot;zn:b&quot; ## [37] &quot;zn:lstat&quot; &quot;indus:chas1&quot; &quot;indus:nox&quot; &quot;indus:rm&quot; ## [41] &quot;indus:age&quot; &quot;indus:dis&quot; &quot;indus:rad&quot; &quot;indus:tax&quot; ## [45] &quot;indus:ptratio&quot; &quot;indus:b&quot; &quot;indus:lstat&quot; &quot;chas1:nox&quot; ## [49] &quot;chas1:rm&quot; &quot;chas1:age&quot; &quot;chas1:dis&quot; &quot;chas1:rad&quot; ## [53] &quot;chas1:tax&quot; &quot;chas1:ptratio&quot; &quot;chas1:b&quot; &quot;chas1:lstat&quot; ## [57] &quot;nox:rm&quot; &quot;nox:age&quot; &quot;nox:dis&quot; &quot;nox:rad&quot; ## [61] &quot;nox:tax&quot; &quot;nox:ptratio&quot; &quot;nox:b&quot; &quot;nox:lstat&quot; ## [65] &quot;rm:age&quot; &quot;rm:dis&quot; &quot;rm:rad&quot; &quot;rm:tax&quot; ## [69] &quot;rm:ptratio&quot; &quot;rm:b&quot; &quot;rm:lstat&quot; &quot;age:dis&quot; ## [73] &quot;age:rad&quot; &quot;age:tax&quot; &quot;age:ptratio&quot; &quot;age:b&quot; ## [77] &quot;age:lstat&quot; &quot;dis:rad&quot; &quot;dis:tax&quot; &quot;dis:ptratio&quot; ## [81] &quot;dis:b&quot; &quot;dis:lstat&quot; &quot;rad:tax&quot; &quot;rad:ptratio&quot; ## [85] &quot;rad:b&quot; &quot;rad:lstat&quot; &quot;tax:ptratio&quot; &quot;tax:b&quot; ## [89] &quot;tax:lstat&quot; &quot;ptratio:b&quot; &quot;ptratio:lstat&quot; &quot;b:lstat&quot; しかし作成された特徴量の数は92で、12足りない。特徴量自身の二乗項が入っていないためだ。もともとの特徴量は13あったので、不足分が1つ足らないような気がするが、これは因子型特徴量のchacがダミー変数化されて2つの特徴量に分かれているためだ。 特徴量自身の二乗項は、I()を使って明示的に含めてやる必要がある。書籍の方に合わせるのであれば、少々面倒だが以下のようにやる。もっと上手いやり方があるかもしれない。 BostonHousing2 &lt;- BostonHousing BostonHousing2$chas %&lt;&gt;% as.numeric() boston_task2 &lt;- makeRegrTask(data = BostonHousing2, target = &quot;medv&quot;) fml &lt;- paste0(&quot;I(&quot;, getTaskFeatureNames(boston_task2), &quot;^2)&quot;, collapse = &quot;+&quot;) fml &lt;- paste0(&quot;~0+&quot;, fml, &quot;+.^2&quot;) boston_task_ex2 &lt;- boston_task2 %&gt;&gt;% cpoModelMatrix(as.formula(fml)) getTaskFeatureNames(boston_task_ex2) ## [1] &quot;I(crim^2)&quot; &quot;I(zn^2)&quot; &quot;I(indus^2)&quot; &quot;I(chas^2)&quot; ## [5] &quot;I(nox^2)&quot; &quot;I(rm^2)&quot; &quot;I(age^2)&quot; &quot;I(dis^2)&quot; ## [9] &quot;I(rad^2)&quot; &quot;I(tax^2)&quot; &quot;I(ptratio^2)&quot; &quot;I(b^2)&quot; ## [13] &quot;I(lstat^2)&quot; &quot;crim&quot; &quot;zn&quot; &quot;indus&quot; ## [17] &quot;chas&quot; &quot;nox&quot; &quot;rm&quot; &quot;age&quot; ## [21] &quot;dis&quot; &quot;rad&quot; &quot;tax&quot; &quot;ptratio&quot; ## [25] &quot;b&quot; &quot;lstat&quot; &quot;crim:zn&quot; &quot;crim:indus&quot; ## [29] &quot;crim:chas&quot; &quot;crim:nox&quot; &quot;crim:rm&quot; &quot;crim:age&quot; ## [33] &quot;crim:dis&quot; &quot;crim:rad&quot; &quot;crim:tax&quot; &quot;crim:ptratio&quot; ## [37] &quot;crim:b&quot; &quot;crim:lstat&quot; &quot;zn:indus&quot; &quot;zn:chas&quot; ## [41] &quot;zn:nox&quot; &quot;zn:rm&quot; &quot;zn:age&quot; &quot;zn:dis&quot; ## [45] &quot;zn:rad&quot; &quot;zn:tax&quot; &quot;zn:ptratio&quot; &quot;zn:b&quot; ## [49] &quot;zn:lstat&quot; &quot;indus:chas&quot; &quot;indus:nox&quot; &quot;indus:rm&quot; ## [53] &quot;indus:age&quot; &quot;indus:dis&quot; &quot;indus:rad&quot; &quot;indus:tax&quot; ## [57] &quot;indus:ptratio&quot; &quot;indus:b&quot; &quot;indus:lstat&quot; &quot;chas:nox&quot; ## [61] &quot;chas:rm&quot; &quot;chas:age&quot; &quot;chas:dis&quot; &quot;chas:rad&quot; ## [65] &quot;chas:tax&quot; &quot;chas:ptratio&quot; &quot;chas:b&quot; &quot;chas:lstat&quot; ## [69] &quot;nox:rm&quot; &quot;nox:age&quot; &quot;nox:dis&quot; &quot;nox:rad&quot; ## [73] &quot;nox:tax&quot; &quot;nox:ptratio&quot; &quot;nox:b&quot; &quot;nox:lstat&quot; ## [77] &quot;rm:age&quot; &quot;rm:dis&quot; &quot;rm:rad&quot; &quot;rm:tax&quot; ## [81] &quot;rm:ptratio&quot; &quot;rm:b&quot; &quot;rm:lstat&quot; &quot;age:dis&quot; ## [85] &quot;age:rad&quot; &quot;age:tax&quot; &quot;age:ptratio&quot; &quot;age:b&quot; ## [89] &quot;age:lstat&quot; &quot;dis:rad&quot; &quot;dis:tax&quot; &quot;dis:ptratio&quot; ## [93] &quot;dis:b&quot; &quot;dis:lstat&quot; &quot;rad:tax&quot; &quot;rad:ptratio&quot; ## [97] &quot;rad:b&quot; &quot;rad:lstat&quot; &quot;tax:ptratio&quot; &quot;tax:b&quot; ## [101] &quot;tax:lstat&quot; &quot;ptratio:b&quot; &quot;ptratio:lstat&quot; &quot;b:lstat&quot; "]
]
